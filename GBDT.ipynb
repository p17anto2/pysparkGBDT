{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finnish-equity",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Import findspark and initialize, then import pyspark and sparkSession and create a Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baking-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"spark://10.0.2.8:7077\").appName(\"Datamake\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-liberia",
   "metadata": {},
   "source": [
    "Create schema and Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "permanent-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType,\\\n",
    "                                FloatType, LongType, DecimalType\n",
    "schema = StructType([ \\\n",
    "                     StructField('index', StringType(), True), \\\n",
    "                     StructField('app_id', LongType(), True), \\\n",
    "                     StructField('app_name', StringType(), True), \\\n",
    "                     StructField('review_id', LongType(), True), \\\n",
    "                     StructField('language', StringType(), True), \\\n",
    "                     StructField('review', StringType(), True), \\\n",
    "                     StructField('timestamp_created', LongType(), True), \\\n",
    "                     StructField('timestamp_updated', LongType(), True), \\\n",
    "                     StructField('recommended', BooleanType(), True), \\\n",
    "                     StructField('votes_helpful', IntegerType(), True), \\\n",
    "                     StructField('votes_funny', IntegerType(), True), \\\n",
    "                     StructField('weighted_vote_score', FloatType(), True), \\\n",
    "                     StructField('comment_count', IntegerType(), True), \\\n",
    "                     StructField('steam_purchase', BooleanType(), True), \\\n",
    "                     StructField('received_for_free', BooleanType(), True), \\\n",
    "                     StructField('written_during_early_access', BooleanType(), True), \\\n",
    "                     StructField('author_steamid', LongType(), True), \\\n",
    "                     StructField('author_num_games_owned', IntegerType(), True), \\\n",
    "                     StructField('author_num_reviews', IntegerType(), True), \\\n",
    "                     StructField('author_playtime_forever', DecimalType(), True), \\\n",
    "                     StructField('author_playtime_last_two_weeks', DecimalType(), True), \\\n",
    "                     StructField('author_playtime_at_review', DecimalType(), True), \\\n",
    "                     StructField('author_last_played', FloatType(), True), \\\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "natural-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = spark.read.csv(\"/home/tolias/Documents/sr_small\", header = True, schema = schema, multiLine = True,\\\n",
    "                    lineSep = \"\\r\")\n",
    "df = df.drop(\"review\", \"index\", \"app_name\", \"language\")\n",
    "df = df.withColumn(\"recommended\",col(\"recommended\").cast(IntegerType()))\n",
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-difficulty",
   "metadata": {},
   "source": [
    "Prepare data for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "incorporate-intent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------+-----------+\n",
      "|features                                                                                                                                         |recommended|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------+-----------+\n",
      "|[292030.0,8.5185598E7,1.611381629E9,1.611381629E9,0.0,0.0,0.0,0.0,1.0,0.0,0.0,7.6561199095369536E16,6.0,2.0,1909.0,1448.0,1909.0,1.61134336E9]   |1          |\n",
      "|[292030.0,8.518525E7,1.61138103E9,1.61138103E9,0.0,0.0,0.0,0.0,1.0,0.0,0.0,7.6561198949504112E16,30.0,10.0,2764.0,2743.0,2674.0,1.611386368E9]   |1          |\n",
      "|[292030.0,8.5185111E7,1.6113808E9,1.6113808E9,0.0,0.0,0.0,0.0,1.0,0.0,0.0,7.6561199090098992E16,5.0,1.0,1061.0,1061.0,1060.0,1.611383808E9]      |1          |\n",
      "|[292030.0,8.5184605E7,1.61137997E9,1.61137997E9,0.0,0.0,0.0,0.0,1.0,0.0,0.0,7.6561199054755376E16,5.0,3.0,5587.0,3200.0,5524.0,1.611383808E9]    |1          |\n",
      "|[292030.0,8.5184287E7,1.611379427E9,1.611379427E9,0.0,0.0,0.0,0.0,1.0,0.0,0.0,7.6561199028326944E16,7.0,4.0,217.0,42.0,217.0,1.610788224E9]      |1          |\n",
      "|[292030.0,8.5184171E7,1.611379264E9,1.611379264E9,0.0,0.0,0.0,0.0,1.0,0.0,0.0,7.6561198170193536E16,11.0,1.0,823.0,823.0,823.0,1.6113792E9]      |1          |\n",
      "|[292030.0,8.5184064E7,1.611379091E9,1.611379091E9,0.0,0.0,0.0,0.0,1.0,0.0,0.0,7.6561198119302816E16,27.0,2.0,4192.0,3398.0,4192.0,1.61135168E9]  |1          |\n",
      "|[292030.0,8.5183602E7,1.611378312E9,1.611378312E9,0.0,0.0,0.0,0.0,1.0,0.0,0.0,7.6561199084188848E16,9.0,1.0,2701.0,0.0,2701.0,1.609671168E9]     |1          |\n",
      "|[292030.0,8.5183227E7,1.611377703E9,1.611377703E9,0.0,0.0,0.0,0.0,1.0,0.0,0.0,7.6561198130808992E16,581.0,17.0,6921.0,222.0,6921.0,1.611317248E9]|1          |\n",
      "|[292030.0,8.5182785E7,1.611377005E9,1.611377005E9,0.0,0.0,0.0,0.0,1.0,0.0,0.0,7.6561198301724112E16,38.0,5.0,2399.0,333.0,2364.0,1.611379072E9]  |1          |\n",
      "|[292030.0,8.5182697E7,1.611376831E9,1.611376831E9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,7.6561199089209584E16,29.0,1.0,5368.0,1471.0,5368.0,1.611371648E9] |1          |\n",
      "|[292030.0,8.5182372E7,1.611376281E9,1.611376281E9,0.0,0.0,0.0,0.0,1.0,0.0,0.0,7.6561198257031328E16,11.0,2.0,508.0,508.0,348.0,1.611386624E9]    |1          |\n",
      "|[292030.0,8.5182067E7,1.611375772E9,1.611375772E9,0.0,0.0,0.0,0.0,1.0,0.0,0.0,7.6561198348941584E16,20.0,1.0,6598.0,29.0,6598.0,1.610715904E9]   |1          |\n",
      "|[292030.0,8.5181146E7,1.611374238E9,1.611374309E9,0.0,0.0,0.0,0.0,1.0,0.0,0.0,7.6561197987104688E16,501.0,23.0,7310.0,0.0,7310.0,1.52555456E9]   |1          |\n",
      "|[292030.0,8.5181114E7,1.611374195E9,1.611374195E9,0.0,0.0,0.0,0.0,1.0,0.0,0.0,7.656119912026312E16,1.0,1.0,3285.0,3084.0,3205.0,1.611385856E9]   |1          |\n",
      "|[292030.0,8.5180815E7,1.611373708E9,1.611373708E9,0.0,0.0,0.0,0.0,1.0,0.0,0.0,7.6561198301696592E16,5.0,1.0,3586.0,0.0,3586.0,1.609390976E9]     |1          |\n",
      "|[292030.0,8.5180734E7,1.611373593E9,1.611373593E9,0.0,0.0,0.0,0.0,1.0,0.0,0.0,7.6561198985671328E16,9.0,1.0,5483.0,2184.0,5483.0,1.611371264E9]  |1          |\n",
      "|[292030.0,8.5180438E7,1.611373087E9,1.611373087E9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,7.6561198149550624E16,66.0,7.0,5442.0,1643.0,5396.0,1.611386624E9] |1          |\n",
      "|[292030.0,8.5180436E7,1.611373086E9,1.611373086E9,0.0,0.0,0.0,0.0,1.0,0.0,0.0,7.656119806559152E16,33.0,1.0,23329.0,177.0,23329.0,1.611219072E9] |1          |\n",
      "|[292030.0,8.5179968E7,1.611372286E9,1.611372286E9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,7.6561198249585968E16,31.0,5.0,2153.0,46.0,2153.0,1.61132544E9]    |1          |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "cols = df.columns\n",
    "cols.remove(\"recommended\")\n",
    "assembler = VectorAssembler(inputCols = cols, outputCol = \"features\")\n",
    "\n",
    "data = assembler.transform(df)\n",
    "data = data.select(\"features\", \"recommended\")\n",
    "data.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "distinct-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "roman-telephone",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0043e83285a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgbt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGBTClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"recommended\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaturesCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprediction_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='recommended',\\\n",
      "\u001b[0;32m~/spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.0.1-bin-hadoop3.2/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.0.1-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/spark-3.0.1-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.0.1-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jupyter/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import time\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "gbt = GBTClassifier(labelCol = \"recommended\", featuresCol = \"features\")\n",
    "train.cache()\n",
    "model = gbt.fit(train)\n",
    "prediction_test = model.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='recommended',\\\n",
    "                                          metricName='accuracy')\n",
    "evaluator.evaluate(prediction_test)\n",
    "duration = (time.time() - t)\n",
    "train.unpersist()\n",
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-segment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
